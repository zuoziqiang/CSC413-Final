{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the model which intent to generate sequences with Shakespeare style."
      ],
      "metadata": {
        "id": "prcAJGrP33Um"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "WXXtDbVHiUd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d8eb61-f091-4901-ee58-72d621e30d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "from collections import Counter\n",
        "import torchtext\n",
        "drive.mount('/content/gdrive')\n",
        "file_path = '/content/gdrive/My Drive/CSC413/harmlet.txt'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we process the data."
      ],
      "metadata": {
        "id": "SuIPUv7BCbve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for line in open(file_path):\n",
        "    if(line!=\"\\n\"):\n",
        "      sentences.append(line[:-1].lstrip())"
      ],
      "metadata": {
        "id": "Vb74DYC2Ci52"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentences))\n",
        "print(sentences[2])\n",
        "print(sentences[200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnykksEDCuYT",
        "outputId": "a5823db2-8a41-4581-c24d-88795e3307ee"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4167\n",
            "Dramatis Personae\n",
            "For it is as the air, invulnerable,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 4456 sentences in harmlet and we chose one of the sentence as sample so that our model can generate the sample after training. "
      ],
      "metadata": {
        "id": "2ChWeKKAMTZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[1040]\n",
        "sample=sentences[1040]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH_LZwNCMa75",
        "outputId": "920fc527-cab0-49a0-a93f-fde657759066"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He closes with you in this consequence:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = list(set(sample)) + [\"<BOS>\", \"<EOS>\"]\n",
        " # A mapping of index => word (string)\n",
        "word_itos = dict(enumerate(word)) \n",
        "word_stoi = {word:index for index, word in word_itos.items()}\n",
        "word_size = len(word)\n",
        "print(word_itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGDULRgDMnTC",
        "outputId": "cab852a8-9f80-46b3-ca0f-31115e7a9698"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: ':', 1: 't', 2: 'q', 3: 'o', 4: 'u', 5: 'n', 6: 'e', 7: 'w', 8: 's', 9: 'i', 10: ' ', 11: 'H', 12: 'c', 13: 'h', 14: 'y', 15: 'l', 16: '<BOS>', 17: '<EOS>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using a RNN model which means it not only produce the token but also produce a hidden state for the next token to produce. Here we bring in two special characters BOS and EOS which repersent the Begining input state and the end state of the sentence. The model start with the input of BOS and stop generate when it produce to the EOS."
      ],
      "metadata": {
        "id": "_ZKgHCVX-oqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model have three parts:\n",
        "\n",
        "1. An **embedding** layer that takes a character index (sparse representation of a one-hot vector\n",
        "   representing the character), and returns an **embedding** ${\\bf x}^{(t)}$ for the character.\n",
        "2. A **recurrent neural network** layer. We will use a `nn.GRU` unit which use folllowing function. At each time step,\n",
        "   this layer will take the previous hidden state ${\\bf h}^{(t-1)}$ and the embedding of\n",
        "   a new generated token ${\\bf x}^{(t)}$ and compute the new hidden state ${\\bf h}^{(t)}$ representing\n",
        "   *tokens not yet generated*."
      ],
      "metadata": {
        "id": "kEOUo3oBF1D1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![function.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "LswWjWjWFO_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. The projection MLP that takes the hidden state ${\\bf h}^{(t)}$\n",
        "   and computes teh distribution of the next character to generate."
      ],
      "metadata": {
        "id": "j_aIkWw0HiHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "eexfjGg9zQv4"
      },
      "outputs": [],
      "source": [
        "class TextGenerator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,    \n",
        "                 embedding_size, \n",
        "                 hidden_size):  \n",
        "        super(TextGenerator, self).__init__()\n",
        "\n",
        "        # Embedding \n",
        "        self.embed = nn.Embedding(num_embeddings=vocab_size, \n",
        "                                  embedding_dim=embedding_size)  \n",
        "\n",
        "        # recurrent neural network\n",
        "        self.rnn = nn.GRU(input_size=embedding_size, \n",
        "                          hidden_size=hidden_size, \n",
        "                          batch_first=True)\n",
        "\n",
        "        # a fully-connect layer that outputs a distribution over\n",
        "        # the next token, given the RNN output\n",
        "        self.proj = nn.Linear(in_features=hidden_size, \n",
        "                              out_features=vocab_size) \n",
        "\n",
        "    def forward(self, inp, hidden=None):\n",
        "        emb = self.embed(inp)                  \n",
        "        output, hidden = self.rnn(emb, hidden) \n",
        "        output = self.proj(output)            \n",
        "        return output, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a sample how we train model base on one sentence of the harmlet.\n",
        "The problem we face is how to caculate the loss. In order to have a loss we should "
      ],
      "metadata": {
        "id": "waMJEKmumDXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextGenerator(word_size, 128, 128)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "senten_ch = [\"<BOS>\"] + list(sample) + [\"<EOS>\"]\n",
        "senten_indices = [word_stoi[ch] for ch in sample]\n",
        "senten_tensor = torch.Tensor(senten_indices).long().unsqueeze(0)\n",
        "all_losses=[]\n",
        "for it in range(1000): \n",
        "    optimizer.zero_grad()\n",
        "    output, hidden =  model(senten_tensor[:,:-1]) \n",
        "    target = senten_tensor[:,1:] \n",
        "    loss = criterion(output.reshape(-1, word_size), \n",
        "               target.reshape(-1))     \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    all_losses.append(float(loss))\n",
        "    if (it+1) % 100 == 0:\n",
        "        print(\"[Iter %d] Loss %f\" % (it+1, float(loss)))\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Learning Curve: Loss per 100 Iteration\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(all_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "8imVWcgbO7ra",
        "outputId": "cea2d997-46d5-4577-f0ea-b2d4fed47d42"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iter 100] Loss 0.024123\n",
            "[Iter 200] Loss 0.006803\n",
            "[Iter 300] Loss 0.003433\n",
            "[Iter 400] Loss 0.002122\n",
            "[Iter 500] Loss 0.001458\n",
            "[Iter 600] Loss 0.001071\n",
            "[Iter 700] Loss 0.000824\n",
            "[Iter 800] Loss 0.000655\n",
            "[Iter 900] Loss 0.000535\n",
            "[Iter 1000] Loss 0.000445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f784d74a750>]"
            ]
          },
          "metadata": {},
          "execution_count": 251
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We build the method that generate the sentence. It takes the model max length of the sentence. it use the front character and the hidden state produce the current character and next character. There are two case we stop the Generation, one is when we reach the max length of the sentence. The other one is when we reach EOS which means we reach the end of the sentence."
      ],
      "metadata": {
        "id": "43stLIqikMJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice there is a paremeter called temperature which I believe is the entropy of this generation. When the temperature going high the character will become more and more ramdom. The reason for that is there is no right answer for this model to generation. This model should be able to generate a whole set of the sentence. However it should also not be too ramdom. It should follow some kind of rules(like grammar)."
      ],
      "metadata": {
        "id": "0MhUNhMYmK9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_sequence(model,word_stoi,word_itos, max_len=100, temperature=0.8):\n",
        "    generated_sequence = \"\"\n",
        "   \n",
        "    inp = torch.Tensor([word_stoi[\"<BOS>\"]]).long()\n",
        "    hidden = None\n",
        "    for p in range(max_len):\n",
        "        output, hidden = model(inp.unsqueeze(0), hidden)\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = int(torch.multinomial(output_dist, 1)[0])\n",
        "        predicted_char = word_itos[top_i]\n",
        "        \n",
        "        if predicted_char == \"<EOS>\":\n",
        "            break\n",
        "        generated_sequence += predicted_char       \n",
        "        inp = torch.Tensor([top_i]).long()\n",
        "    return generated_sequence"
      ],
      "metadata": {
        "id": "W7zG7F6zPnQu"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_sequence(model, word_stoi,word_itos,temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXcf2HnvPr2E",
        "outputId": "b1f078ab-ca4e-416e-a7c2-68b5853cdbd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you in this consequence::e:closes with you in this consequence::closes with you in this consequence:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we intent to train our model for the single batch"
      ],
      "metadata": {
        "id": "VvHU7PejeZym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = list(set([w for s in sentences for w in s])) + [\"<BOS>\", \"<EOS>\"]\n",
        "vocab_itos = dict(enumerate(vocab))\n",
        "vocab_stoi = {word:index for index, word in vocab_itos.items()}\n",
        "size_all = len(vocab)\n",
        "print(vocab_itos)\n",
        "def train(model, data,vocab_stoi,vocab_itos,size_all, batch_size=1, num_epochs=1, lr=0.001, print_every=100):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    it = 0\n",
        "    data_batch=[]\n",
        "    loss_a=[]\n",
        "    while (len(data_batch)<batch_size):\n",
        "      a=random.randint(0,len(data)-1)\n",
        "      if data[a] not in data_batch:\n",
        "        data_batch.append(data[a])\n",
        "    for e in range(num_epochs):\n",
        "        # get training set\n",
        "        avg_loss = 0\n",
        "        for senten in data_batch:\n",
        "            se_ch = [\"<BOS>\"] + list(senten) + [\"<EOS>\"]\n",
        "            se_indices = [vocab_stoi[ch] for ch in se_ch]\n",
        "            se_tensor = torch.Tensor(se_indices).long().unsqueeze(0)\n",
        "            target = se_tensor[:,1:]\n",
        "            inp = se_tensor[:,:-1]\n",
        "            optimizer.zero_grad()\n",
        "            output, hidden =  model(inp)\n",
        "            loss = criterion(output.reshape(-1, size_all),\n",
        "                 target.reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss\n",
        "            it += 1 \n",
        "            if it % print_every == 0:\n",
        "                print(\"[Iter %d] Loss %f\" % (it+1, float(avg_loss/print_every)))\n",
        "                print(\"    \" + sample_sequence(model,vocab_stoi,vocab_itos, 140, 0.8))\n",
        "                loss_a.append(float(avg_loss/print_every))\n",
        "                avg_loss = 0\n",
        "    plt.figure()\n",
        "    plt.plot(all_losses)\n",
        "model = TextGenerator(size_all, 128, 128)"
      ],
      "metadata": {
        "id": "x1BHM9BsLGJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aece691-8c03-41f2-9d8c-b63708db65b9"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'I', 1: '.', 2: ':', 3: ',', 4: 'C', 5: 'T', 6: ')', 7: 'R', 8: 'b', 9: 'i', 10: 'n', 11: 'y', 12: 'k', 13: 'p', 14: 'J', 15: '?', 16: 'S', 17: 'z', 18: '!', 19: 'B', 20: '-', 21: 't', 22: 'f', 23: '[', 24: ';', 25: 'q', 26: 'E', 27: 'U', 28: 'G', 29: 'm', 30: 'W', 31: 'h', 32: 'D', 33: 'Y', 34: 's', 35: 'd', 36: '&', 37: 'x', 38: 'V', 39: 'l', 40: 'j', 41: 'r', 42: 'M', 43: 'P', 44: 'a', 45: '\"', 46: 'O', 47: 'e', 48: 'w', 49: 'L', 50: 'v', 51: 'c', 52: '1', 53: \"'\", 54: 'o', 55: 'A', 56: 'N', 57: 'u', 58: 'K', 59: ']', 60: 'g', 61: ' ', 62: 'H', 63: 'F', 64: 'Q', 65: '(', 66: '<BOS>', 67: '<EOS>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train(model, sentences,vocab_stoi,size_all, batch_size=1, num_epochs=10, lr=0.004, print_every=1)\n",
        "train(model, sentences,vocab_stoi,vocab_itos,size_all, batch_size=32, num_epochs=100, lr=0.004, print_every=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QhbLYLL0M4Sk",
        "outputId": "f8dcd691-7d65-43a2-b5d9-52b9f5afaf11"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iter 101] Loss 0.075766\n",
            "    be I lol, ot therphise be winst thin.\n",
            "[Iter 201] Loss 0.107953\n",
            "    Wh you. O my1 I rupine.\n",
            "[Iter 301] Loss 0.101540\n",
            "    Whey soth the strand demi-nateech Lou.\n",
            "[Iter 401] Loss 0.078033\n",
            "    Exeunt.\n",
            "[Iter 501] Loss 0.054956\n",
            "    Ham. Ay, so, God dingle spies.\n",
            "[Iter 601] Loss 0.045676\n",
            "    When sorrows come, they come not single spies.\n",
            "[Iter 701] Loss 0.045823\n",
            "    And from her fair and unpolluted flesh  \n",
            "[Iter 801] Loss 0.047650\n",
            "    Exeunt.\n",
            "[Iter 901] Loss 0.005362\n",
            "    be otherwise.\n",
            "[Iter 1001] Loss 0.009498\n",
            "    Why seems it so particular with thee?\n",
            "[Iter 1101] Loss 0.014020\n",
            "    A noise within: 'Let her come in.'\n",
            "[Iter 1201] Loss 0.018521\n",
            "    Exeunt.\n",
            "[Iter 1301] Loss 0.023082\n",
            "    Ham. Ay, so, God b' wi' ye!\n",
            "[Iter 1401] Loss 0.029932\n",
            "    As had he been incorps'd and demi-natur'd\n",
            "[Iter 1501] Loss 0.035373\n",
            "    Before mine uncle. I'll observe his looks;\n",
            "[Iter 1601] Loss 0.039415\n",
            "    Exeunt.\n",
            "[Iter 1701] Loss 0.004832\n",
            "    Exeunt.\n",
            "[Iter 1801] Loss 0.008543\n",
            "    Rey. Ay, my lord,\n",
            "[Iter 1901] Loss 0.012964\n",
            "    Had made his course t' illume that part of heaven\n",
            "[Iter 2001] Loss 0.017471\n",
            "    Ham. Ay, so, God b' wi' ye!\n",
            "[Iter 2101] Loss 0.022035\n",
            "    Ham. Ay, sir, what of him?\n",
            "[Iter 2201] Loss 0.028921\n",
            "    In noise so rude against me?\n",
            "[Iter 2301] Loss 0.034491\n",
            "    be otherwise.\n",
            "[Iter 2401] Loss 0.038533\n",
            "    Exeunt.\n",
            "[Iter 2501] Loss 0.004798\n",
            "    Hath turn'd itself on me. Lo, here I lie,\n",
            "[Iter 2601] Loss 0.008425\n",
            "    Ham. Ay, sir, what of him?\n",
            "[Iter 2701] Loss 0.012856\n",
            "    be otherwise.\n",
            "[Iter 2801] Loss 0.017356\n",
            "    Pol. This business is well ended.\n",
            "[Iter 2901] Loss 0.021848\n",
            "    As had he been incorps'd and demi-natur'd\n",
            "[Iter 3001] Loss 0.028716\n",
            "    A noise within: 'Let her come in.'\n",
            "[Iter 3101] Loss 0.034319\n",
            "    Exeunt.\n",
            "[Iter 3201] Loss 0.038344\n",
            "    be otherwise.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basicly we chose one batch of the sentences of the harmlet to train our model and try to generate each sentence as close as possibble. At the end the model will fit the batch of sentences."
      ],
      "metadata": {
        "id": "UxaYXHJVh35x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(10):\n",
        "  print(sample_sequence(model,vocab_stoi,vocab_itos, temperature=0.8))\n",
        "print(\"==================================\")\n",
        "for x in range(10):\n",
        "  print(sample_sequence(model,vocab_stoi,vocab_itos, temperature=1.0))\n",
        "print(\"==================================\")\n",
        "for x in range(10):\n",
        "  print(sample_sequence(model,vocab_stoi,vocab_itos, temperature=1.5))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbzja4wvq_6V",
        "outputId": "9e300b5d-24a9-4844-ddea-0751e7c311c6"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For I mine eyes will rivet to his face,\n",
            "Ham. 'The mobled queen'?\n",
            "defence?\n",
            "Hecuba.\n",
            "Ham. 'The mobled queen'?\n",
            "Hecuba.\n",
            "Hor. Of that I shall have also cause to speak,\n",
            "Mess. Save Yourself, my lord:\n",
            "Hecuba.\n",
            "Mess. Save Yourself, my lord:\n",
            "==================================\n",
            "defence?\n",
            "And prey on garbage.\n",
            "And prey on garbage.\n",
            "And prey on garbage.\n",
            "To you alone.\n",
            "Hecuba.\n",
            "Guos. Faith, there has been much to do on both sides; and the nation\n",
            "Ham. 'The mobled queen'?\n",
            "Guil. Happy in that we are not over-happy.\n",
            "defence?\n",
            "==================================\n",
            "of our fellowship, by the conband queen 'therestallone.s; Nifay,\n",
            "Will you be rul'd by me?\n",
            "Ros.] Faitrad:\n",
            "That he which hath your ngown not wewnhan kind!\n",
            "Hor. Of that I shall have also cause to speak,\n",
            "Hecuba.\n",
            "To Norway, uncle of young Fortinbras,\n",
            "Mess. Save Yourself, my lord:\n",
            "[to so Hamlet's Father.\n",
            "King. Go seek him there. [To Attendxven to his manen, to necxtban] do e?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see because we only train the model with only one of the batch, the model may overfit the batch and always generate the origin sentence from the batch. We don't want that , therefore we should feed the model more batchs."
      ],
      "metadata": {
        "id": "0bBzbUTMsNO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batchs(model, data,vocab_stoi,vocab_itos,size_all, batch_size=1, num_epochs=1, lr=0.001, print_every=100):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    it = 0\n",
        "    random.shuffle(data)\n",
        "    count=0\n",
        "    while(count+batch_size<len(data)):\n",
        "      for e in range(num_epochs):\n",
        "        # get training set\n",
        "        avg_loss = 0\n",
        "        for senten in data[count:count+batch_size]:\n",
        "            se_ch = [\"<BOS>\"] + list(senten) + [\"<EOS>\"]\n",
        "            se_indices = [vocab_stoi[ch] for ch in se_ch]\n",
        "            se_tensor = torch.Tensor(se_indices).long().unsqueeze(0)\n",
        "            target = se_tensor[:,1:]\n",
        "            inp = se_tensor[:,:-1]\n",
        "            optimizer.zero_grad()\n",
        "            output, hidden =  model(inp)\n",
        "            loss = criterion(output.reshape(-1, size_all),\n",
        "                 target.reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss\n",
        "            it += 1 \n",
        "            if it % print_every == 0:\n",
        "                print(\"[Iter %d] Loss %f\" % (it+1, float(avg_loss/print_every)))\n",
        "                print(\"    \" + sample_sequence(model,vocab_stoi,vocab_itos, 140, 0.8))\n",
        "                avg_loss = 0\n",
        "      count+=batch_size"
      ],
      "metadata": {
        "id": "x4igzWeiuryH"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextGenerator(size_all, 128, 128)\n",
        "train_batchs(model, sentences,vocab_stoi,vocab_itos,size_all, batch_size=32, num_epochs=10, lr=0.004, print_every=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmFTzL4Hv2bW",
        "outputId": "27f883e5-65b3-41ca-85b1-ab537dbf9d46"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iter 101] Loss 0.074606\n",
            "    Ham. At mer.\n",
            "[Iter 201] Loss 0.103452\n",
            "    Kis't blout burhe and mor;t your wighat Lord.\n",
            "[Iter 301] Loss 0.096992\n",
            "    Excombe to thacat the blush ann thoughts the it mace\n",
            "[Iter 401] Loss 0.239292\n",
            "    Ham. Whigut.\n",
            "[Iter 501] Loss 0.163801\n",
            "    Ham. Sir, in me you go sere.\n",
            "[Iter 601] Loss 0.123243\n",
            "    Lord. My fatelg theas a the Nemnean comest a houndleshy princes at a sent omth.\n",
            "[Iter 701] Loss 0.553091\n",
            "    And my lae come thou that tha a won'tn.\n",
            "[Iter 801] Loss 0.271380\n",
            "    Hase parille. Ir.\n",
            "[Iter 901] Loss 0.017462\n",
            "    I am and jud;\n",
            "[Iter 1001] Loss 0.159447\n",
            "    Ham. Dind ans;\n",
            "[Iter 1101] Loss 0.095429\n",
            "    [Laertes theseres the Freany famlt doenc! 'tous ove.\n",
            "[Iter 1201] Loss 0.059275\n",
            "    Ham. I humbly thou; well, well, well.\n",
            "[Iter 1301] Loss 0.613389\n",
            "    Enter Hamle.\n",
            "[Iter 1401] Loss 0.208671\n",
            "    The bell then wptase, [Econder Hamlet wivent,\n",
            "[Iter 1501] Loss 0.117669\n",
            "    Th' observ- qute,\n",
            "[Iter 1601] Loss 0.084448\n",
            "    Hor. What is't, my lord? Wik y pics agaill. a deary more youl de to now-\n",
            "[Iter 1701] Loss 0.046999\n",
            "    Po and speak! I have.\n",
            "[Iter 1801] Loss 0.040273\n",
            "    Ham. I what.\n",
            "[Iter 1901] Loss 0.036083\n",
            "    Exeunt [all but Hamlet].\n",
            "[Iter 2001] Loss 0.243625\n",
            "    Thi whit i, be po of grey anly\n",
            "[Iter 2101] Loss 0.129277\n",
            "    This must be known; which, bee ewervre my gravel.\n",
            "[Iter 2201] Loss 0.082071\n",
            "    We will bestow bous me by third Oratio! Why may not\n",
            "[Iter 2301] Loss 0.595668\n",
            "    O he ave thing to out soit.\n",
            "[Iter 2401] Loss 0.244734\n",
            "    O havy jud? Irth wish word drawfat.\n",
            "[Iter 2501] Loss 0.013694\n",
            "    That I might be the room our gian Cast,\n",
            "[Iter 2601] Loss 0.166410\n",
            "    Rome thy, now sping ordsome-\n",
            "[Iter 2701] Loss 0.107270\n",
            "    Extis ber. 'Tis here!\n",
            "[Iter 2801] Loss 0.077010\n",
            "    Ham. Why here the ing of sleed-\n",
            "[Iter 2901] Loss 0.669394\n",
            "    Guil. My honow per.\n",
            "[Iter 3001] Loss 0.272877\n",
            "    \n",
            "[Iter 3101] Loss 0.158986\n",
            "    \n",
            "[Iter 3201] Loss 0.123576\n",
            "    \n",
            "[Iter 3301] Loss 0.047840\n",
            "    Scene II.\n",
            "[Iter 3401] Loss 0.043463\n",
            "    Oph. No, my good lord; but, as by do nom thies dowis my good for the ghost!\n",
            "[Iter 3501] Loss 0.042631\n",
            "    Hor. O rovingeas now, I means!\n",
            "[Iter 3601] Loss 0.264942\n",
            "    Whis persther,n, what the re and alls weals yout myfer.\n",
            "[Iter 3701] Loss 0.151679\n",
            "    In o myort not\n",
            "[Iter 3801] Loss 0.103044\n",
            "    Ham. How if I answer no.\n",
            "[Iter 3901] Loss 0.577811\n",
            "    Dop'lcural weret wereks I wo slay.\n",
            "[Iter 4001] Loss 0.262761\n",
            "    Hamlet is I wosear you aslel.\n",
            "[Iter 4101] Loss 0.016180\n",
            "    Queen. Nay, thou the nigh of Denmark.\n",
            "[Iter 4201] Loss 0.139264\n",
            "    I dot so.\n",
            "[Iter 4301] Loss 0.093139\n",
            "    not.\n",
            "[Iter 4401] Loss 0.073901\n",
            "    not at all.\n",
            "[Iter 4501] Loss 0.724559\n",
            "    A vir in fair.\n",
            "[Iter 4601] Loss 0.323409\n",
            "    \n",
            "[Iter 4701] Loss 0.210748\n",
            "    No natould!  fatiellldelston this offectifergisencrien and a ther fall there my nary com.\n",
            "[Iter 4801] Loss 0.149126\n",
            "    \n",
            "[Iter 4901] Loss 0.048708\n",
            "    \n",
            "[Iter 5001] Loss 0.056861\n",
            "    \n",
            "[Iter 5101] Loss 0.061447\n",
            "    \n",
            "[Iter 5201] Loss 0.224386\n",
            "    \n",
            "[Iter 5301] Loss 0.142754\n",
            "    \n",
            "[Iter 5401] Loss 0.109814\n",
            "    \n",
            "[Iter 5501] Loss 0.603656\n",
            "     I drown'd, flistight thuse of sumu, shik'd drays, my thour y-\n",
            "[Iter 5601] Loss 0.291022\n",
            "    Good Knought.\n",
            "[Iter 5701] Loss 0.018172\n",
            "    Re breins nat a flis ever. But wet warth our ford ome mat and manede hand?\n",
            "[Iter 5801] Loss 0.178934\n",
            "    Queendsevilsendse.\n",
            "[Iter 5901] Loss 0.109692\n",
            "    Queen. Hamled of breen obe of sperial'd\n",
            "[Iter 6001] Loss 0.082685\n",
            "    sense.\n",
            "[Iter 6101] Loss 0.619974\n",
            "    Ham.\n",
            "[Iter 6201] Loss 0.274553\n",
            "    [How fathou. I will rivet a lobeen'?\n",
            "[Iter 6301] Loss 0.188905\n",
            "    Toghey, and peal upost nows younationg's father seal'ds part rerpo to tho the macent match an tell!\n",
            "[Iter 6401] Loss 0.147440\n",
            "    Exeunt.\n",
            "[Iter 6501] Loss 0.039240\n",
            "    Pol. Turnd hites hies\n",
            "[Iter 6601] Loss 0.051706\n",
            "    Ham. Nother the twas shat, of youther the odd purtas tos in, and he do not part;\n",
            "[Iter 6701] Loss 0.058185\n",
            "    Of mighty opposites.\n",
            "[Iter 6801] Loss 0.276744\n",
            "    Whis want.\n",
            "[Iter 6901] Loss 0.180523\n",
            "    Eare it.\n",
            "[Iter 7001] Loss 0.145043\n",
            "    Whiff'd hpartind in the the the th' sea-jy youthn hught- but to hes's may the st is meper the dare thate sea-goon to the remet?\n",
            "[Iter 7101] Loss 0.563308\n",
            "    Ham. Witive advy you.]\n",
            "[Iter 7201] Loss 0.309310\n",
            "    But even this.\n",
            "[Iter 7301] Loss 0.016450\n",
            "    Hor. I beseech you.\n",
            "[Iter 7401] Loss 0.193717\n",
            "    For. I harmurst thits.\n",
            "[Iter 7501] Loss 0.128492\n",
            "    To the by soolow of to to eplefe to brkit!\n",
            "[Iter 7601] Loss 0.107089\n",
            "    Ham. I Detlenper we custom hoblesell'd,\n",
            "[Iter 7701] Loss 0.592062\n",
            "    Queen. A awy mongee heath the ound and best solves too stilles, a lovere ity,  \n",
            "[Iter 7801] Loss 0.296531\n",
            "    Oph. Pray you come to this favoor  goted to isees,\n",
            "[Iter 7901] Loss 0.214251\n",
            "    Oph. No marm. Rark. But a sraif int,\n",
            "[Iter 8001] Loss 0.175661\n",
            "    they?\n",
            "[Iter 8101] Loss 0.053907\n",
            "    As youn a my Lines and you withe\n",
            "[Iter 8201] Loss 0.065960\n",
            "    Exit Messenger.\n",
            "[Iter 8301] Loss 0.072610\n",
            "    And keppoul;\n",
            "[Iter 8401] Loss 0.254930\n",
            "    Ham. Ecturitis my ood not with lit listes ay?\n",
            "[Iter 8501] Loss 0.170898\n",
            "    That comindeed dracck too here offart,\n",
            "[Iter 8601] Loss 0.144564\n",
            "     not then wford?\n",
            "[Iter 8701] Loss 0.578904\n",
            "    Dobervand and to me.\n",
            "[Iter 8801] Loss 0.335017\n",
            "    Reant a peal strusenn. Comant aniusenstre of the mour ho, and and still\n",
            "[Iter 8901] Loss 0.021403\n",
            "    Queen. Come away.\n",
            "[Iter 9001] Loss 0.169725\n",
            "    I ha'd ishera'd isene hutelf, catet elf;\n",
            "[Iter 9101] Loss 0.124548\n",
            "    Reconse ive coll For to daglay bo  give a thy seepear infeenmine of of more lords no hagher o\n",
            "[Iter 9201] Loss 0.103664\n",
            "    I ha't!\n",
            "[Iter 9301] Loss 0.638143\n",
            "    master's daughtruembrat to thes right a a a a a self-\n",
            "[Iter 9401] Loss 0.319464\n",
            "    Hag. Thinger the swer.\n",
            "[Iter 9501] Loss 0.216747\n",
            "    tragedians it,  \n",
            "[Iter 9601] Loss 0.168147\n",
            "    Laer. Well, cout me in the kenel knoth in how hisragel,\n",
            "[Iter 9701] Loss 0.065074\n",
            "    tray. Yut the hell roe in that hines have's hile\n",
            "[Iter 9801] Loss 0.075800\n",
            "    When will, thou have se proag. Anot fied al in thog other. Roil, gother.\n",
            "[Iter 9901] Loss 0.075980\n",
            "    But hill how not?\n",
            "[Iter 10001] Loss 0.264324\n",
            "    Roastre, we ber of lits upos now make of may infoth me dosus not the wo'see, earted are to you bow dy is, his he of them sire,  \n",
            "[Iter 10101] Loss 0.187180\n",
            "    Ham. What for my lisess.\n",
            "[Iter 10201] Loss 0.148160\n",
            "    Ber. It con is mad your Whe will not me gave cokis pay be your I woill not speak no powl. What mor of dryour on the not stim was thee of we \n",
            "[Iter 10301] Loss 0.582826\n",
            "    My hen ther Pold you now plaid bear Poown?\n",
            "[Iter 10401] Loss 0.321495\n",
            "    Ham. Buzz!\n",
            "[Iter 10501] Loss 0.022472\n",
            "    Pol. What strom.\n",
            "[Iter 10601] Loss 0.185267\n",
            "    Hor. A him wal tim, sas are acck.\n",
            "[Iter 10701] Loss 0.137222\n",
            "    father?\n",
            "[Iter 10801] Loss 0.109892\n",
            "    Rey. Aonse or it instal lade.\n",
            "[Iter 10901] Loss 0.628336\n",
            "    What's It so ferlve\n",
            "[Iter 11001] Loss 0.307094\n",
            "    Exerpastergum,\n",
            "[Iter 11101] Loss 0.232845\n",
            "    Clown. (sings)\n",
            "[Iter 11201] Loss 0.186733\n",
            "    King. Thation\n",
            "[Iter 11301] Loss 0.052286\n",
            "    But the will have touration. Will the will have chies foun me.\n",
            "[Iter 11401] Loss 0.068458\n",
            "    omme cho, would this ming. To fiounte,\n",
            "[Iter 11501] Loss 0.074012\n",
            "    Exitty, in fear.\n",
            "[Iter 11601] Loss 0.254577\n",
            "    eco Pros; of this this thim, most' is prave\n",
            "[Iter 11701] Loss 0.197512\n",
            "    So in the youn haven, areten. Wim struen; harh chis most end\n",
            "[Iter 11801] Loss 0.168460\n",
            "    Ham. It well bad,\n",
            "[Iter 11901] Loss 0.622874\n",
            "    ex.\n",
            "[Iter 12001] Loss 0.344205\n",
            "    Ros.  \n",
            "[Iter 12101] Loss 0.021742\n",
            "    King. O heave you swut bephmenot foe spnom. O halet, no dot, it mart, How doneity lown ants,\n",
            "[Iter 12201] Loss 0.176432\n",
            "    again.\n",
            "[Iter 12301] Loss 0.131808\n",
            "    O, say!\n",
            "[Iter 12401] Loss 0.122214\n",
            "    liquor.\n",
            "[Iter 12501] Loss 0.637547\n",
            "    Is cappeed;\n",
            "[Iter 12601] Loss 0.361525\n",
            "    And wan'riilonsts falles moult by thy nod in that fasid to patis it.\n",
            "[Iter 12701] Loss 0.263465\n",
            "    His in ot or trulponto good!\n",
            "[Iter 12801] Loss 0.213489\n",
            "    Flents of the receir stand a orrrbund,\n",
            "[Iter 12901] Loss 0.067330\n",
            "    You haside] Onol finevent; uss oo the sporthe the shal too that,\n",
            "[Iter 13001] Loss 0.076116\n",
            "    Mar. My good, or har.'d for ging of that,\n",
            "[Iter 13101] Loss 0.076248\n",
            "    Mar. My good indisude passiing wordso, lordisme. You in the Casith] Hay. Give sh theire, no lessen partillll upisend in that, and the with y\n",
            "[Iter 13201] Loss 0.273065\n",
            "    What pame, no the cup a aly\n",
            "[Iter 13301] Loss 0.213092\n",
            "    Here fulloultion come frount\n",
            "[Iter 13401] Loss 0.173593\n",
            "    Led by a dear by holy, i\n",
            "[Iter 13501] Loss 0.633643\n",
            "    That virs ass.\n",
            "[Iter 13601] Loss 0.406174\n",
            "    But verteer !\n",
            "[Iter 13701] Loss 0.033048\n",
            "    For wad cervieve shere! bad ble nodod thour his wilde vow'd.\n",
            "[Iter 13801] Loss 0.160621\n",
            "    As thence of. Couse? O, saintorru! Sarream\n",
            "[Iter 13901] Loss 0.133457\n",
            "    Wiwhs. Luento of nat nation thener proughcest of If Hamlet\n",
            "[Iter 14001] Loss 0.111011\n",
            "    my lich, town our sul any the ears yowak\n",
            "[Iter 14101] Loss 0.629652\n",
            "    That itny of quer wille, and or to madamemembbith casilen I cord, from Hamlet:\n",
            "[Iter 14201] Loss 0.362242\n",
            "    Thate deisure\n",
            "[Iter 14301] Loss 0.281582\n",
            "    Os my abour wish. Sade, no lirester ant it, bity cous sirch uppthere hade thy nothere shall, ho, so so natht,\n",
            "[Iter 14401] Loss 0.224482\n",
            "    Carve thy of it! the state in speaks leaville, and my so not fot in mer of ther abia,\n",
            "[Iter 14501] Loss 0.057154\n",
            "    The Kiter of the epenat is be thiell callll. The Kis\n",
            "[Iter 14601] Loss 0.073745\n",
            "    omplet, and theyer.\n",
            "[Iter 14701] Loss 0.081337\n",
            "    I will bestow my some to cre sowk; thee, my livok twely. Cqueessure hay a drisure the to the from to thiest,\n",
            "[Iter 14801] Loss 0.267970\n",
            "    Speak farher of latere mared.\n",
            "[Iter 14901] Loss 0.210448\n",
            "    Queen. So he that oud's senmow.\n",
            "[Iter 15001] Loss 0.189527\n",
            "    If't brothere King from a virtartldemat fllows ther polds quader to une a gen, not be in ind'p, s to a he swaste,\n",
            "[Iter 15101] Loss 0.592139\n",
            "    Ent agarits lisers flfest rate and sede, Whendertlembrasts, I wed and disceek\n",
            "[Iter 15201] Loss 0.386221\n",
            "    As thatret fersin; therers not in chuncti;\n",
            "[Iter 15301] Loss 0.031901\n",
            "    Ham. Bit, I know hil us nour play, I dagain\n",
            "[Iter 15401] Loss 0.200805\n",
            "    Enter Ras,chfowner to beather letion our let bed;\n",
            "[Iter 15501] Loss 0.168746\n",
            "    To speeche bent it Prro'tion where prallomes is of Fold, an prceme whing! Wos, wherfy the priel,\n",
            "[Iter 15601] Loss 0.157050\n",
            "    I'll dotu; and Guildenstern.\n",
            "[Iter 15701] Loss 0.562316\n",
            "    Enter Hamlet.\n",
            "[Iter 15801] Loss 0.303707\n",
            "    Osr. Of Laertes thice neither ever this see vor!\n",
            "[Iter 15901] Loss 0.245358\n",
            "    Ham. Wome, now stursern set is wher'd ane nobbre she yous now this?\n",
            "[Iter 16001] Loss 0.211982\n",
            "    hither?\n",
            "[Iter 16101] Loss 0.049051\n",
            "    Laer. Ay my lord,\n",
            "[Iter 16201] Loss 0.070018\n",
            "    King. All kepither in ly to the by do spain day show yourevinotion bning have there?\n",
            "[Iter 16301] Loss 0.086695\n",
            "    Laer. Ay me the my lord,\n",
            "[Iter 16401] Loss 0.252973\n",
            "    Hor. Horrot, Ham. Horraletun] Sosrion,\n",
            "[Iter 16501] Loss 0.195783\n",
            "    Hor. OF re\n",
            "[Iter 16601] Loss 0.180066\n",
            "    Ham. So lordaming,\n",
            "[Iter 16701] Loss 0.706963\n",
            "    Rout.\n",
            "[Iter 16801] Loss 0.446688\n",
            "    You mother onst not how ish'd here qulaigh'd,\n",
            "[Iter 16901] Loss 0.043528\n",
            "    Exell.\n",
            "[Iter 17001] Loss 0.182150\n",
            "    Ham. One.  \n",
            "[Iter 17101] Loss 0.161339\n",
            "    HAMLET.'\n",
            "[Iter 17201] Loss 0.148542\n",
            "    HAMLET.'\n",
            "[Iter 17301] Loss 0.625977\n",
            "    Ham. Goo dosting naturtion.\n",
            "[Iter 17401] Loss 0.383811\n",
            "    Wherefore's itercesh is of or, sir;,\n",
            "[Iter 17501] Loss 0.312906\n",
            "    I wour int entul? t good Corne, Guir coz\n",
            "[Iter 17601] Loss 0.267314\n",
            "    Clown. Home 'ts 'tis saar.\n",
            "[Iter 17701] Loss 0.059767\n",
            "    Ho, lave and my lord,\n",
            "[Iter 17801] Loss 0.081781\n",
            "    That bretio my my this sar dood my our dis;\n",
            "[Iter 17901] Loss 0.094701\n",
            "    Then I han theiln\n",
            "[Iter 18001] Loss 0.268614\n",
            "    SCit.\n",
            "[Iter 18101] Loss 0.211643\n",
            "    Ham. Who, I?\n",
            "[Iter 18201] Loss 0.200626\n",
            "    Opthirsrirse?\n",
            "[Iter 18301] Loss 0.610399\n",
            "    This seeve she it the acted, so robatiritedtyed shaloke that be crite.\n",
            "[Iter 18401] Loss 0.423953\n",
            "    peennaloker.- cond shat shape so rue you rinkds blard\n",
            "[Iter 18501] Loss 0.036054\n",
            "    There's it'dill so a shoulds breakily of the true beeve.\n",
            "[Iter 18601] Loss 0.158929\n",
            "    Thee en cortinstinios off hide his concis and tervemembs will be slake ay afroughsin lifth a rambsle you me fruse ficid;\n",
            "[Iter 18701] Loss 0.153936\n",
            "    hine,\n",
            "[Iter 18801] Loss 0.151162\n",
            "    I both sawsshlatiche so able to bade he ischan gooe so be our judgmenters.\n",
            "[Iter 18901] Loss 0.590879\n",
            "    Givicinse liss all so ax'd tide as to his gean the the slave suld Poll.\n",
            "[Iter 19001] Loss 0.352184\n",
            "    As to from we this to the to has fall, juve, to th my lett ast thou satters.]\n",
            "[Iter 19101] Loss 0.296812\n",
            "    Ham. In happy time.\n",
            "[Iter 19201] Loss 0.273553\n",
            "    Ham. In hows fortice to have us.\n",
            "[Iter 19301] Loss 0.072256\n",
            "    Ham. Shis shall bet I hing,\n",
            "[Iter 19401] Loss 0.083737\n",
            "    To you you mour\n",
            "[Iter 19501] Loss 0.094322\n",
            "    And garr'd!\n",
            "[Iter 19601] Loss 0.276622\n",
            "    Ghas this swe ell.\n",
            "[Iter 19701] Loss 0.243678\n",
            "    I the borter bife to burdicer on fits we ouking.\n",
            "[Iter 19801] Loss 0.211036\n",
            "    New, Lonnos sten?\n",
            "[Iter 19901] Loss 0.566624\n",
            "    Ham. I a promech, minds me,\n",
            "[Iter 20001] Loss 0.416316\n",
            "    The procct all beregck vollick sweemins; so good with be shatid sath whing makes mad sal. In do do beseak thee mick there fset\n",
            "[Iter 20101] Loss 0.033542\n",
            "    Queen. If it be,\n",
            "[Iter 20201] Loss 0.160822\n",
            "    Queent list not you?\n",
            "[Iter 20301] Loss 0.134827\n",
            "    Who shat under offe,\n",
            "[Iter 20401] Loss 0.135537\n",
            "    The had the carraste officer.\n",
            "[Iter 20501] Loss 0.567210\n",
            "    Host curear dear the mutit the mutarn there?\n",
            "[Iter 20601] Loss 0.331653\n",
            "    And what for forget!\n",
            "[Iter 20701] Loss 0.273963\n",
            "    Hos. Neencous nost it\n",
            "[Iter 20801] Loss 0.242835\n",
            "    Clown. Very the fanesecenever migether noince still. Snour to brosr. Loorving smop of see the stose say. [Polonius].\n",
            "[Iter 20901] Loss 0.064363\n",
            "    This pray. How necell' guit to sit unows of hear watch an ast of speeloqeyir preak of must\n",
            "[Iter 21001] Loss 0.085100\n",
            "    Clown. (Sintledy of and all of an the goot not prosed\n",
            "[Iter 21101] Loss 0.090208\n",
            "    That show not the fates\n",
            "[Iter 21201] Loss 0.283568\n",
            "    Exeund.\n",
            "[Iter 21301] Loss 0.223886\n",
            "    That of of sing a son. Scene so. I hour reconensiecen? Hor. E'en so, You trembune.\n",
            "[Iter 21401] Loss 0.204060\n",
            "    To tery butt,\n",
            "[Iter 21501] Loss 0.599079\n",
            "    If old duratar thoughtoke aut thes means?\n",
            "[Iter 21601] Loss 0.432484\n",
            "    King. Ol shate,\n",
            "[Iter 21701] Loss 0.037185\n",
            "    To you are moun are a words?\n",
            "[Iter 21801] Loss 0.192360\n",
            "    Exewn ing are ling like, if on'd it main ould the grais ou the grawerhat the me chous dide, and oughought in' fim' do gorath it;\n",
            "[Iter 21901] Loss 0.176513\n",
            "    King. Let do faff! How of Na gone,\n",
            "[Iter 22001] Loss 0.171377\n",
            "    \n",
            "[Iter 22101] Loss 0.588789\n",
            "    The lay, gooneat they eand the m\n",
            "[Iter 22201] Loss 0.337418\n",
            "    Oph. (Sings)\n",
            "[Iter 22301] Loss 0.283591\n",
            "    Of spion me-\n",
            "[Iter 22401] Loss 0.272807\n",
            "    Ham. And hous to do,\n",
            "[Iter 22501] Loss 0.051878\n",
            "    Oph.(- Swite\n",
            "[Iter 22601] Loss 0.068803\n",
            "    Eto th sece'\n",
            "[Iter 22701] Loss 0.089254\n",
            "    And Cimus thell.\n",
            "[Iter 22801] Loss 0.283101\n",
            "    Things) Why, ir me in he theese me of bed- glikes us up a skfnow I drencell;\n",
            "[Iter 22901] Loss 0.248499\n",
            "    Ham. We pooop'sites her, in pathursecyet [TGhaerts ads the be we; there.\n",
            "[Iter 23001] Loss 0.222996\n",
            "    Ham. Why,\n",
            "[Iter 23101] Loss 0.620140\n",
            "    Liose thour ins fed in words but is giver in a the cony moress,\n",
            "[Iter 23201] Loss 0.469651\n",
            "    Why he had more paress my maisseye they rataturdow hasts.\n",
            "[Iter 23301] Loss 0.034004\n",
            "    Fror, to my heat I king the King his our beat I\n",
            "[Iter 23401] Loss 0.169444\n",
            "    Thal me the to man an therein may my agagarce, I Oard\n",
            "[Iter 23501] Loss 0.142828\n",
            "    Pertch my mortelircourweeseese conest, his my deyep thee to't thery bray.\n",
            "[Iter 23601] Loss 0.137513\n",
            "    To kircourbend,\n",
            "[Iter 23701] Loss 0.571700\n",
            "    As such voun us fore betweriching.\n",
            "[Iter 23801] Loss 0.366588\n",
            "    Swe gastatius, thing ind th't why chave bysed\n",
            "[Iter 23901] Loss 0.302882\n",
            "    Ham. Ind of crran. Bor and belsives\n",
            "[Iter 24001] Loss 0.281222\n",
            "    In honourable you of-bys of Thitendended.\n",
            "[Iter 24101] Loss 0.061382\n",
            "    Wive not fang the without as\n",
            "[Iter 24201] Loss 0.085358\n",
            "    Ham. Byerfo,\n",
            "[Iter 24301] Loss 0.098499\n",
            "    And holance fan the com so, my my mother th ner?\n",
            "[Iter 24401] Loss 0.295157\n",
            "    Ros. Mand speak alldoblegson th' ear lord!\n",
            "[Iter 24501] Loss 0.239498\n",
            "    How some\n",
            "[Iter 24601] Loss 0.233328\n",
            "    Ham. I prove,\n",
            "[Iter 24701] Loss 0.578348\n",
            "    Hecubbacy and fat? The so may you.\n",
            "[Iter 24801] Loss 0.416186\n",
            "    To the cornglentsion are,\n",
            "[Iter 24901] Loss 0.040775\n",
            "    Spord sperine.\n",
            "[Iter 25001] Loss 0.163718\n",
            "    Oenstway trill solevend fitel;\n",
            "[Iter 25101] Loss 0.154694\n",
            "    The raste him gam hep this distill fright ner that woour leverhy cath not of leaste her led lpors. Su, Ham. Sind fets worse,\n",
            "[Iter 25201] Loss 0.168206\n",
            "    That I best, as that I he salt ense mudiry much mad,\n",
            "[Iter 25301] Loss 0.535269\n",
            "    Ham. Won.\n",
            "[Iter 25401] Loss 0.318384\n",
            "    Ham. Why,\n",
            "[Iter 25501] Loss 0.288247\n",
            "    of reveri.\n",
            "[Iter 25601] Loss 0.255963\n",
            "    Ham. Why to bear Ophon 'w ing mirrall sme.\n",
            "[Iter 25701] Loss 0.069870\n",
            "    Ham. Whe King,\n",
            "[Iter 25801] Loss 0.087568\n",
            "    To his gracese the know our but spould it to my liok pat sepse did you all. Marry, wevene st sele of at of heaven.\n",
            "[Iter 25901] Loss 0.104867\n",
            "    King. Alas, and Hymen to me did you not lirs, speronost of heaven.\n",
            "[Iter 26001] Loss 0.264221\n",
            "    Queen. Alay,\n",
            "[Iter 26101] Loss 0.223825\n",
            "    Exit.\n",
            "[Iter 26201] Loss 0.227483\n",
            "    Queen. I'll be the fould Your the more I whould of t' was sty!\n",
            "[Iter 26301] Loss 0.592041\n",
            "    Ros and yo your this bet. Sood manwt.\n",
            "[Iter 26401] Loss 0.424951\n",
            "    Guilden's I, cly pittleat, to that I\n",
            "[Iter 26501] Loss 0.034117\n",
            "    Ham. Be could nomespers congrailefits my lord?\n",
            "[Iter 26601] Loss 0.187594\n",
            "    Bted jueguch the nows\n",
            "[Iter 26701] Loss 0.180716\n",
            "    By his lete sugerive ah, sive a pown ifts fill. No, cond thatewrratief,\n",
            "[Iter 26801] Loss 0.191339\n",
            "    Guil. My lord.\n",
            "[Iter 26901] Loss 0.531318\n",
            "    The on hinkt I, iven,\n",
            "[Iter 27001] Loss 0.345247\n",
            "    Twiletere formorerat'rime to but shood man.\n",
            "[Iter 27101] Loss 0.308806\n",
            "    A within. Look your heaven!\n",
            "[Iter 27201] Loss 0.286277\n",
            "    Laer. No.\n",
            "[Iter 27301] Loss 0.069999\n",
            "    Oph.\n",
            "[Iter 27401] Loss 0.097813\n",
            "    Schon I!\n",
            "[Iter 27501] Loss 0.125085\n",
            "    He entos to despocritundels of head, I canffree-\n",
            "[Iter 27601] Loss 0.265325\n",
            "    Bid is wrow aill wormsents to said,\n",
            "[Iter 27701] Loss 0.245770\n",
            "    Thath stion gers the his will, wemstrat it the cause,\n",
            "[Iter 27801] Loss 0.227816\n",
            "    For both wrothing the arraper.]\n",
            "[Iter 27901] Loss 0.545015\n",
            "    [Rer it be with his his lhow the look and Hamlet is encerry quirtard, I show speed Hamles thill, my lord, upe and be encerow the know Fertal\n",
            "[Iter 28001] Loss 0.401859\n",
            "    [Exit. Lor. I the busight,\n",
            "[Iter 28101] Loss 0.040237\n",
            "    Enter thil, my growss\n",
            "[Iter 28201] Loss 0.177326\n",
            "    low. Wems my mows\n",
            "[Iter 28301] Loss 0.183975\n",
            "    Oph. 'Tis and\n",
            "[Iter 28401] Loss 0.177801\n",
            "    To sholdierves then\n",
            "[Iter 28501] Loss 0.570043\n",
            "    The corst swas boocklat not wasy\n",
            "[Iter 28601] Loss 0.384813\n",
            "    To beto, to and by freending cir'- Osmst; revil. Yous frontunod Layer Hamlemes;\n",
            "[Iter 28701] Loss 0.330978\n",
            "    gratiens.\n",
            "[Iter 28801] Loss 0.303413\n",
            "    Guil. Lor the gounseaks my pion disty now.\n",
            "[Iter 28901] Loss 0.066114\n",
            "    Enter Queen.\n",
            "[Iter 29001] Loss 0.088631\n",
            "    Heall guiall ben come,\n",
            "[Iter 29101] Loss 0.115032\n",
            "    Ham. Why?\n",
            "[Iter 29201] Loss 0.275139\n",
            "    joike thy there\n",
            "[Iter 29301] Loss 0.241059\n",
            "    No known, geven burist like to geave ton here dotes in he sulould.  \n",
            "[Iter 29401] Loss 0.227820\n",
            "    Deed memory, geven medghy you and ereatrows, [Volay;\n",
            "[Iter 29501] Loss 0.560437\n",
            "    Ha., Bra lord?\n",
            "[Iter 29601] Loss 0.429395\n",
            "    Ham. Ay, and mark.\n",
            "[Iter 29701] Loss 0.036863\n",
            "    What have halowith pees on heavens.\n",
            "[Iter 29801] Loss 0.192203\n",
            "    And him. (ites. My betherible! It my liky rentisins and likiet is be arrown-\n",
            "[Iter 29901] Loss 0.161118\n",
            "    Of\n",
            "[Iter 30001] Loss 0.155537\n",
            "    A killly knoudy,\n",
            "[Iter 30101] Loss 0.541925\n",
            "    Oph. Lay!\n",
            "[Iter 30201] Loss 0.393113\n",
            "    Oph. Nay the bentono to him must deart of futy digt wertich, home,\n",
            "[Iter 30301] Loss 0.339141\n",
            "    What with this af a de to together. Goughther lose topeter Hor teest mone.\n",
            "[Iter 30401] Loss 0.318187\n",
            "    Ham. What prair?\n",
            "[Iter 30501] Loss 0.057654\n",
            "    Exost tunk know'd, and trieutch his. I this faid the King.  \n",
            "[Iter 30601] Loss 0.092930\n",
            "    Queen the Kine tich, I this and lester hosoncould have it hoser.\n",
            "[Iter 30701] Loss 0.126640\n",
            "    Thou know'st of this bleath and leran wolion boson You doth what faver.\n",
            "[Iter 30801] Loss 0.277685\n",
            "    Os him, that for our with the wa 'see thing malse ess, my her cofffollf hees.\n",
            "[Iter 30901] Loss 0.255149\n",
            "    Laer. Layery his corguall to the deartell. The him, lird. Let here then the bellowise is me seenchet. Mack\n",
            "[Iter 31001] Loss 0.247997\n",
            "    Happril me me me foorklts the bright, it waiters starke t'ent.\n",
            "[Iter 31101] Loss 0.576067\n",
            "    'ther!\n",
            "[Iter 31201] Loss 0.433652\n",
            "    Comother, foul\n",
            "[Iter 31301] Loss 0.038442\n",
            "    That your wather Pol. The lord.\n",
            "[Iter 31401] Loss 0.140786\n",
            "    Woul. I your\n",
            "[Iter 31501] Loss 0.162660\n",
            "    What sur King, and Polong mothout yeevuver nout sat.\n",
            "[Iter 31601] Loss 0.179338\n",
            "    [Ting this vacrryerty andase. Alexagistronir ow yeart.\n",
            "[Iter 31701] Loss 0.564913\n",
            "    By the pher withouch\n",
            "[Iter 31801] Loss 0.380229\n",
            "    Exit head pursen the my longel,\n",
            "[Iter 31901] Loss 0.343068\n",
            "    To the of Eread, icld the doth your mry ronger, my mor faticadeld fears.\n",
            "[Iter 32001] Loss 0.333589\n",
            "    But the purging thie! O vence; thocen\n",
            "[Iter 32101] Loss 0.065204\n",
            "    A suh, perne our Polontow'd,\n",
            "[Iter 32201] Loss 0.098926\n",
            "    For Hamn'd like orf in for gentlel, flof miden the mand's plentolents the seand sunge.\n",
            "[Iter 32301] Loss 0.112326\n",
            "    Ham. Sonius.  \n",
            "[Iter 32401] Loss 0.303809\n",
            "    But yourgha?\n",
            "[Iter 32501] Loss 0.263956\n",
            "    Forve no wat show ha?\n",
            "[Iter 32601] Loss 0.250814\n",
            "    Ophelia,'-\n",
            "[Iter 32701] Loss 0.557298\n",
            "    That is not.\n",
            "[Iter 32801] Loss 0.440948\n",
            "    Ham. What your dre is gecters out the stoubgentrualiothers thatill is the mark younrunnce.\n",
            "[Iter 32901] Loss 0.044235\n",
            "    Laer. Think it to doe,\n",
            "[Iter 33001] Loss 0.186144\n",
            "    Exit sevily concrrornould, all wash him the ce peronnabius pracrrarrs'onot; but don thy himcius. No peendum!\n",
            "[Iter 33101] Loss 0.182206\n",
            "    Scene IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIm. Wuth a shous stus, and and your lonown, thy as that but a she but trask, ards Nonones,\n",
            "[Iter 33201] Loss 0.192641\n",
            "    nge is but a stou wandl and to past, fand! or mous, my lord?\n",
            "[Iter 33301] Loss 0.494463\n",
            "    My think verInce\n",
            "[Iter 33401] Loss 0.347430\n",
            "    'It your- two?\n",
            "[Iter 33501] Loss 0.311240\n",
            "    And with eread\n",
            "[Iter 33601] Loss 0.307639\n",
            "    1. Play. Ay, my lord, with to time\n",
            "[Iter 33701] Loss 0.065424\n",
            "    Uthy that you herenty love on the cruse su is me!\n",
            "[Iter 33801] Loss 0.094133\n",
            "    Hor. 'Tis counreasy onstresy. He he have so love mean,\n",
            "[Iter 33901] Loss 0.109618\n",
            "    musty.\n",
            "[Iter 34001] Loss 0.283137\n",
            "    Ham. Do your peasres they)\n",
            "[Iter 34101] Loss 0.274763\n",
            "    Guil. I hovuld that, a ' swour dins his her fortacle my her not,\n",
            "[Iter 34201] Loss 0.261353\n",
            "    them not,\n",
            "[Iter 34301] Loss 0.628058\n",
            "    And a vay.\n",
            "[Iter 34401] Loss 0.469653\n",
            "    worle I hop wearn\n",
            "[Iter 34501] Loss 0.045119\n",
            "    Would that.\n",
            "[Iter 34601] Loss 0.172132\n",
            "    Polony th hereen reak the you somen im.\n",
            "[Iter 34701] Loss 0.180280\n",
            "    Spenand ambo, 't, and app'r\n",
            "[Iter 34801] Loss 0.193865\n",
            "    wolon shis lord, his lord, have mattet, his a hibing in an aiglatterpes and amlown.- Whaverf,\n",
            "[Iter 34901] Loss 0.525223\n",
            "    Clow mre yo me.\n",
            "[Iter 35001] Loss 0.389465\n",
            "    The logs.-  yout to it to you dasaking,\n",
            "[Iter 35101] Loss 0.327627\n",
            "    For Hamlet.\n",
            "[Iter 35201] Loss 0.312893\n",
            "    Of you reancee goindglue Of bain loved it truill.'\n",
            "[Iter 35301] Loss 0.067388\n",
            "    Of that- Rosis Horde-man so seave-making one the sweeding?\n",
            "[Iter 35401] Loss 0.106143\n",
            "    thist the what that crannitosing, the that there is acplay.\n",
            "[Iter 35501] Loss 0.129270\n",
            "    it not?\n",
            "[Iter 35601] Loss 0.279612\n",
            "    Guen the I what my coming our make gour you a our   larders].\n",
            "[Iter 35701] Loss 0.256053\n",
            "    Exeunt.\n",
            "[Iter 35801] Loss 0.256435\n",
            "    Clow'd by the seen see!\n",
            "[Iter 35901] Loss 0.601921\n",
            "    [Exit for thalestera! Cownink to thatio youl!\n",
            "[Iter 36001] Loss 0.474675\n",
            "    Ham. O beting my       sure with Queen.]\n",
            "[Iter 36101] Loss 0.048418\n",
            "    I such for my lis are  \n",
            "[Iter 36201] Loss 0.169655\n",
            "    Ham. Ar have hosre so word way is am dist own ing is have in the us.\n",
            "[Iter 36301] Loss 0.169737\n",
            "    O, hand the did the hef Folot is dor the did lats are don the praninter dor ot and love, speak, am see vary.\n",
            "[Iter 36401] Loss 0.190596\n",
            "    Be ho!\n",
            "[Iter 36501] Loss 0.564970\n",
            "    Lair, the reak the form, God the forsth,\n",
            "[Iter 36601] Loss 0.367655\n",
            "    Guil?\n",
            "[Iter 36701] Loss 0.344603\n",
            "    Ham. Murther?\n",
            "[Iter 36801] Loss 0.345178\n",
            "    Be from a famore, Hamlet.\n",
            "[Iter 36901] Loss 0.070078\n",
            "    But the up.\n",
            "[Iter 37001] Loss 0.105749\n",
            "    Oph. Ay, my down. Ay, artup;\n",
            "[Iter 37101] Loss 0.123361\n",
            "    Exeunt.\n",
            "[Iter 37201] Loss 0.280009\n",
            "    To not could I madn ourtle.\n",
            "[Iter 37301] Loss 0.255443\n",
            "    To his with nothie. A mie.\n",
            "[Iter 37401] Loss 0.248034\n",
            "    Ham. Loart. will that whather?\n",
            "[Iter 37501] Loss 0.605893\n",
            "    How you comen.]\n",
            "[Iter 37601] Loss 0.446837\n",
            "    [Exitl,\n",
            "[Iter 37701] Loss 0.034590\n",
            "    King. Goot wead, all the kingan?\n",
            "[Iter 37801] Loss 0.172775\n",
            "    All my my seemed live of be bughemined ing fines favou helia?\n",
            "[Iter 37901] Loss 0.188565\n",
            "    Thesell. Fiost, for ming! Mearthdon the is be to hedgeendanyrill.\n",
            "[Iter 38001] Loss 0.204929\n",
            "    Alet,\n",
            "[Iter 38101] Loss 0.538808\n",
            "    itick mother fore it nothis,\n",
            "[Iter 38201] Loss 0.385867\n",
            "    Sincell he fore\n",
            "[Iter 38301] Loss 0.340272\n",
            "    It all is on to eem,\n",
            "[Iter 38401] Loss 0.329530\n",
            "    If usod 't mourntry revissing.\n",
            "[Iter 38501] Loss 0.054924\n",
            "    id I keent to pardiouchat its loom,\n",
            "[Iter 38601] Loss 0.102842\n",
            "    Ber. Syotle in will willdie,\n",
            "[Iter 38701] Loss 0.119419\n",
            "    But stancatlanntles.\n",
            "[Iter 38801] Loss 0.276767\n",
            "    Iut.\n",
            "[Iter 38901] Loss 0.254741\n",
            "    King. Tho cay\n",
            "[Iter 39001] Loss 0.267835\n",
            "    Scene II.\n",
            "[Iter 39101] Loss 0.562041\n",
            "    A distreor he shery arme. Ande.\n",
            "[Iter 39201] Loss 0.418630\n",
            "    loul! I with himpone deere cullike is ereent thesion? be done,\n",
            "[Iter 39301] Loss 0.039204\n",
            "    I thing to so gone,\n",
            "[Iter 39401] Loss 0.176325\n",
            "    Exits I the is art. Whelf. I I will bear trom. The lart beate,\n",
            "[Iter 39501] Loss 0.172805\n",
            "    you truth the King.\n",
            "[Iter 39601] Loss 0.197215\n",
            "    Exit Ghost.\n",
            "[Iter 39701] Loss 0.494302\n",
            "    Ham.  \n",
            "[Iter 39801] Loss 0.342981\n",
            "    Ham. Aett I be gret Haml.\n",
            "[Iter 39901] Loss 0.317709\n",
            "    Guil. I ding meyir.\n",
            "[Iter 40001] Loss 0.304833\n",
            "    Go of harter Ham. And read, th thou trust on.\n",
            "[Iter 40101] Loss 0.067449\n",
            "    Ham. I sharrguiselmed lett, my lord? How theart\n",
            "[Iter 40201] Loss 0.093032\n",
            "    lown. Ewngunience head the fer sho,\n",
            "[Iter 40301] Loss 0.129354\n",
            "    You the gaivatiendru. E'en a face.\n",
            "[Iter 40401] Loss 0.286122\n",
            "     I say sooter?\n",
            "[Iter 40501] Loss 0.249063\n",
            "    Ham. I'\n",
            "[Iter 40601] Loss 0.252656\n",
            "     offenter? Thesio gone;\n",
            "[Iter 40701] Loss 0.568280\n",
            "    Tron will bur ar.\n",
            "[Iter 40801] Loss 0.451799\n",
            "    Nautwends me Yere?\n",
            "[Iter 40901] Loss 0.044827\n",
            "    And In me), even you peak\n",
            "[Iter 41001] Loss 0.192177\n",
            "    Before the whink fad:\n",
            "[Iter 41101] Loss 0.190152\n",
            "    And will but of hitcracters\n",
            "[Iter 41201] Loss 0.193308\n",
            "    Ham. Goow sen\n",
            "[Iter 41301] Loss 0.492622\n",
            "    We I,\n",
            "[Iter 41401] Loss 0.337931\n",
            "    Guil. The rear.\n",
            "[Iter 41501] Loss 0.320086\n",
            "    Yet his mather, makes\n",
            "[Iter 41601] Loss 0.327476\n",
            "    What you, seer pation,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(10):\n",
        "  print(sample_sequence(model,vocab_stoi,vocab_itos, temperature=0.8))\n",
        "print(\"==================================\")\n",
        "for x in range(10):\n",
        "  print(sample_sequence(model,vocab_stoi,vocab_itos, temperature=1.0))\n",
        "print(\"==================================\")\n",
        "for x in range(10):\n",
        "  print(sample_sequence(model,vocab_stoi,vocab_itos, temperature=1.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxHyyBEk0nZf",
        "outputId": "ea30d7ff-07f5-4efd-a7ee-f90433b992cd"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of he will the will no pation,\n",
            "Yet I,\n",
            "Wull him. Prish cost and and dosoo?\n",
            "Laer. The will this madiark\n",
            "That shat she reard\n",
            "Swear.\n",
            "Withoser then Pringuertion his nate\n",
            "Clown. Ths may, Hamlete not no the remove noth in't to that namet I,\n",
            "Swear.\n",
            "Yet I,\n",
            "==================================\n",
            "Guil. Pright hefur mights ye I,\n",
            "Swear.\n",
            "Well minisuletse that sornturser,\n",
            "Guil. Prisfen as in his is to reard be? Thou my lord?  \n",
            "Swear, and Is mlam. Ho purthis me delf, nose com with figation dim. Thath be did will not with dose \n",
            "Swear.\n",
            "Ist times  \n",
            "Whosco?\n",
            "Now he we breuch and the with father, and Noptes thou, makem me it?\n",
            "Theromaske the  \n",
            "==================================\n",
            "Now Prome ad withem I Dowson agh my doroughou,\n",
            "Theer gink,\n",
            "is lighte\n",
            "Thuncive daing hear.\n",
            "Quilaine.  \n",
            "Yeth burial inquausets arwer quimet his quier,\n",
            "Is! Lelf mindeecd, bo you, orawent Lithem.\n",
            "No,' rourly,. O, in his know, he tidelf likn made\n",
            "scson of give re lyem.\n",
            "Queen. Pallk she grewhes, th' shall not pourson,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the model is much better than before. "
      ],
      "metadata": {
        "id": "RDwTeo1o0v4R"
      }
    }
  ]
}